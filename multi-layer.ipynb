{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc4b45a4",
   "metadata": {},
   "source": [
    "# Clothing Image Classifier 2\n",
    "This notbook I build a clothing image classifier using A **fully connected nueral network** wih 2 *fully connected layers* and the FashionMNIST dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9e1f0d",
   "metadata": {},
   "source": [
    "# Define Transform "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38f51c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms \n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5), (0.5)) # normalize \n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9370648",
   "metadata": {},
   "source": [
    "# Data & Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1bd2e333",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "\n",
    "#datasets \n",
    "trainset = torchvision.datasets.FashionMNIST(root='./data', download=True, \n",
    "                                             train=True, transform=transform)\n",
    "\n",
    "testset = torchvision.datasets.FashionMNIST(root='./data', download=True,\n",
    "                                            train=False, transform=transform)\n",
    "\n",
    "# dataloaders\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=1, \n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=1, \n",
    "                                         shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fda88d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classes \n",
    "classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c3922e",
   "metadata": {},
   "source": [
    "# Check DataLoader Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c4b0675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dress\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# show img function \n",
    "# PyToch sees images as (Channel, Height, Width), but numpy sees them as (Height, width, Channel)\n",
    "# Function is needed to make he switch \n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unormalize\n",
    "    npimg = img.numpy()     #\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0))) # transpose the tensor in order to match the expected shape\n",
    "\n",
    "# get image batch from trainset \n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# show the image\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print(' | '.join(f'{classes[labels[i]]}' for i in range(len(labels))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be053bd9",
   "metadata": {},
   "source": [
    "## Create Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35437672",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class FCN2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FCN2, self).__init__()\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(28 * 28, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 1024)\n",
    "        self.fc3 = nn.Linear(1024, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Flatten \n",
    "        x = x.view(-1, 28 * 28)\n",
    "        \n",
    "        # Run through decision layers\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x \n",
    "fcn2 = FCN2()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abac06de",
   "metadata": {},
   "source": [
    "## Loss function and Back Prop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2054a0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim \n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(fcn2.parameters(), lr=0.001, momentum=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca10ceb",
   "metadata": {},
   "source": [
    "## Train Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae30c83a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1, Batch   400] loss: 2.144\n",
      "[Epoch 1, Batch   800] loss: 1.833\n",
      "[Epoch 1, Batch  1200] loss: 1.431\n",
      "[Epoch 1, Batch  1600] loss: 1.175\n",
      "[Epoch 1, Batch  2000] loss: 1.024\n",
      "[Epoch 1, Batch  2400] loss: 0.956\n",
      "[Epoch 1, Batch  2800] loss: 0.871\n",
      "[Epoch 1, Batch  3200] loss: 0.885\n",
      "[Epoch 1, Batch  3600] loss: 0.715\n",
      "[Epoch 1, Batch  4000] loss: 0.789\n",
      "[Epoch 1, Batch  4400] loss: 0.736\n",
      "[Epoch 1, Batch  4800] loss: 0.716\n",
      "[Epoch 1, Batch  5200] loss: 0.771\n",
      "[Epoch 1, Batch  5600] loss: 0.745\n",
      "[Epoch 1, Batch  6000] loss: 0.720\n",
      "[Epoch 1, Batch  6400] loss: 0.689\n",
      "[Epoch 1, Batch  6800] loss: 0.612\n",
      "[Epoch 1, Batch  7200] loss: 0.631\n",
      "[Epoch 1, Batch  7600] loss: 0.573\n",
      "[Epoch 1, Batch  8000] loss: 0.637\n",
      "[Epoch 1, Batch  8400] loss: 0.585\n",
      "[Epoch 1, Batch  8800] loss: 0.638\n",
      "[Epoch 1, Batch  9200] loss: 0.740\n",
      "[Epoch 1, Batch  9600] loss: 0.667\n",
      "[Epoch 1, Batch 10000] loss: 0.614\n",
      "[Epoch 1, Batch 10400] loss: 0.639\n",
      "[Epoch 1, Batch 10800] loss: 0.554\n",
      "[Epoch 1, Batch 11200] loss: 0.569\n",
      "[Epoch 1, Batch 11600] loss: 0.552\n",
      "[Epoch 1, Batch 12000] loss: 0.544\n",
      "[Epoch 1, Batch 12400] loss: 0.561\n",
      "[Epoch 1, Batch 12800] loss: 0.574\n",
      "[Epoch 1, Batch 13200] loss: 0.603\n",
      "[Epoch 1, Batch 13600] loss: 0.533\n",
      "[Epoch 1, Batch 14000] loss: 0.535\n",
      "[Epoch 1, Batch 14400] loss: 0.567\n",
      "[Epoch 1, Batch 14800] loss: 0.618\n",
      "[Epoch 1, Batch 15200] loss: 0.658\n",
      "[Epoch 1, Batch 15600] loss: 0.544\n",
      "[Epoch 1, Batch 16000] loss: 0.551\n",
      "[Epoch 1, Batch 16400] loss: 0.531\n",
      "[Epoch 1, Batch 16800] loss: 0.541\n",
      "[Epoch 1, Batch 17200] loss: 0.484\n",
      "[Epoch 1, Batch 17600] loss: 0.449\n",
      "[Epoch 1, Batch 18000] loss: 0.521\n",
      "[Epoch 1, Batch 18400] loss: 0.496\n",
      "[Epoch 1, Batch 18800] loss: 0.533\n",
      "[Epoch 1, Batch 19200] loss: 0.467\n",
      "[Epoch 1, Batch 19600] loss: 0.466\n",
      "[Epoch 1, Batch 20000] loss: 0.521\n",
      "[Epoch 1, Batch 20400] loss: 0.579\n",
      "[Epoch 1, Batch 20800] loss: 0.473\n",
      "[Epoch 1, Batch 21200] loss: 0.495\n",
      "[Epoch 1, Batch 21600] loss: 0.528\n",
      "[Epoch 1, Batch 22000] loss: 0.491\n",
      "[Epoch 1, Batch 22400] loss: 0.530\n",
      "[Epoch 1, Batch 22800] loss: 0.454\n",
      "[Epoch 1, Batch 23200] loss: 0.499\n",
      "[Epoch 1, Batch 23600] loss: 0.466\n",
      "[Epoch 1, Batch 24000] loss: 0.496\n",
      "[Epoch 1, Batch 24400] loss: 0.533\n",
      "[Epoch 1, Batch 24800] loss: 0.546\n",
      "[Epoch 1, Batch 25200] loss: 0.538\n",
      "[Epoch 1, Batch 25600] loss: 0.501\n",
      "[Epoch 1, Batch 26000] loss: 0.481\n",
      "[Epoch 1, Batch 26400] loss: 0.500\n",
      "[Epoch 1, Batch 26800] loss: 0.445\n",
      "[Epoch 1, Batch 27200] loss: 0.451\n",
      "[Epoch 1, Batch 27600] loss: 0.478\n",
      "[Epoch 1, Batch 28000] loss: 0.509\n",
      "[Epoch 1, Batch 28400] loss: 0.518\n",
      "[Epoch 1, Batch 28800] loss: 0.519\n",
      "[Epoch 1, Batch 29200] loss: 0.466\n",
      "[Epoch 1, Batch 29600] loss: 0.499\n",
      "[Epoch 1, Batch 30000] loss: 0.448\n",
      "[Epoch 1, Batch 30400] loss: 0.482\n",
      "[Epoch 1, Batch 30800] loss: 0.464\n",
      "[Epoch 1, Batch 31200] loss: 0.391\n",
      "[Epoch 1, Batch 31600] loss: 0.476\n",
      "[Epoch 1, Batch 32000] loss: 0.439\n",
      "[Epoch 1, Batch 32400] loss: 0.531\n",
      "[Epoch 1, Batch 32800] loss: 0.525\n",
      "[Epoch 1, Batch 33200] loss: 0.447\n",
      "[Epoch 1, Batch 33600] loss: 0.393\n",
      "[Epoch 1, Batch 34000] loss: 0.397\n",
      "[Epoch 1, Batch 34400] loss: 0.477\n",
      "[Epoch 1, Batch 34800] loss: 0.413\n",
      "[Epoch 1, Batch 35200] loss: 0.507\n",
      "[Epoch 1, Batch 35600] loss: 0.476\n",
      "[Epoch 1, Batch 36000] loss: 0.493\n",
      "[Epoch 1, Batch 36400] loss: 0.516\n",
      "[Epoch 1, Batch 36800] loss: 0.463\n",
      "[Epoch 1, Batch 37200] loss: 0.478\n",
      "[Epoch 1, Batch 37600] loss: 0.412\n",
      "[Epoch 1, Batch 38000] loss: 0.490\n",
      "[Epoch 1, Batch 38400] loss: 0.444\n",
      "[Epoch 1, Batch 38800] loss: 0.507\n",
      "[Epoch 1, Batch 39200] loss: 0.561\n",
      "[Epoch 1, Batch 39600] loss: 0.453\n",
      "[Epoch 1, Batch 40000] loss: 0.558\n",
      "[Epoch 1, Batch 40400] loss: 0.448\n",
      "[Epoch 1, Batch 40800] loss: 0.390\n",
      "[Epoch 1, Batch 41200] loss: 0.528\n",
      "[Epoch 1, Batch 41600] loss: 0.431\n",
      "[Epoch 1, Batch 42000] loss: 0.439\n",
      "[Epoch 1, Batch 42400] loss: 0.429\n",
      "[Epoch 1, Batch 42800] loss: 0.366\n",
      "[Epoch 1, Batch 43200] loss: 0.508\n",
      "[Epoch 1, Batch 43600] loss: 0.453\n",
      "[Epoch 1, Batch 44000] loss: 0.383\n",
      "[Epoch 1, Batch 44400] loss: 0.405\n",
      "[Epoch 1, Batch 44800] loss: 0.422\n",
      "[Epoch 1, Batch 45200] loss: 0.478\n",
      "[Epoch 1, Batch 45600] loss: 0.420\n",
      "[Epoch 1, Batch 46000] loss: 0.447\n",
      "[Epoch 1, Batch 46400] loss: 0.381\n",
      "[Epoch 1, Batch 46800] loss: 0.459\n",
      "[Epoch 1, Batch 47200] loss: 0.459\n",
      "[Epoch 1, Batch 47600] loss: 0.407\n",
      "[Epoch 1, Batch 48000] loss: 0.434\n",
      "[Epoch 1, Batch 48400] loss: 0.422\n",
      "[Epoch 1, Batch 48800] loss: 0.486\n",
      "[Epoch 1, Batch 49200] loss: 0.430\n",
      "[Epoch 1, Batch 49600] loss: 0.385\n",
      "[Epoch 1, Batch 50000] loss: 0.517\n",
      "[Epoch 1, Batch 50400] loss: 0.370\n",
      "[Epoch 1, Batch 50800] loss: 0.488\n",
      "[Epoch 1, Batch 51200] loss: 0.408\n",
      "[Epoch 1, Batch 51600] loss: 0.361\n",
      "[Epoch 1, Batch 52000] loss: 0.436\n",
      "[Epoch 1, Batch 52400] loss: 0.473\n",
      "[Epoch 1, Batch 52800] loss: 0.427\n",
      "[Epoch 1, Batch 53200] loss: 0.556\n",
      "[Epoch 1, Batch 53600] loss: 0.449\n",
      "[Epoch 1, Batch 54000] loss: 0.382\n",
      "[Epoch 1, Batch 54400] loss: 0.416\n",
      "[Epoch 1, Batch 54800] loss: 0.353\n",
      "[Epoch 1, Batch 55200] loss: 0.453\n",
      "[Epoch 1, Batch 55600] loss: 0.472\n",
      "[Epoch 1, Batch 56000] loss: 0.395\n",
      "[Epoch 1, Batch 56400] loss: 0.462\n",
      "[Epoch 1, Batch 56800] loss: 0.428\n",
      "[Epoch 1, Batch 57200] loss: 0.323\n",
      "[Epoch 1, Batch 57600] loss: 0.440\n",
      "[Epoch 1, Batch 58000] loss: 0.405\n",
      "[Epoch 1, Batch 58400] loss: 0.416\n",
      "[Epoch 1, Batch 58800] loss: 0.372\n",
      "[Epoch 1, Batch 59200] loss: 0.468\n",
      "[Epoch 1, Batch 59600] loss: 0.420\n",
      "[Epoch 1, Batch 60000] loss: 0.383\n",
      "[Epoch 2, Batch   400] loss: 0.407\n",
      "[Epoch 2, Batch   800] loss: 0.439\n",
      "[Epoch 2, Batch  1200] loss: 0.376\n",
      "[Epoch 2, Batch  1600] loss: 0.473\n",
      "[Epoch 2, Batch  2000] loss: 0.364\n",
      "[Epoch 2, Batch  2400] loss: 0.378\n",
      "[Epoch 2, Batch  2800] loss: 0.346\n",
      "[Epoch 2, Batch  3200] loss: 0.394\n",
      "[Epoch 2, Batch  3600] loss: 0.373\n",
      "[Epoch 2, Batch  4000] loss: 0.401\n",
      "[Epoch 2, Batch  4400] loss: 0.424\n",
      "[Epoch 2, Batch  4800] loss: 0.376\n",
      "[Epoch 2, Batch  5200] loss: 0.435\n",
      "[Epoch 2, Batch  5600] loss: 0.357\n",
      "[Epoch 2, Batch  6000] loss: 0.379\n",
      "[Epoch 2, Batch  6400] loss: 0.338\n",
      "[Epoch 2, Batch  6800] loss: 0.359\n",
      "[Epoch 2, Batch  7200] loss: 0.349\n",
      "[Epoch 2, Batch  7600] loss: 0.391\n",
      "[Epoch 2, Batch  8000] loss: 0.397\n",
      "[Epoch 2, Batch  8400] loss: 0.363\n",
      "[Epoch 2, Batch  8800] loss: 0.429\n",
      "[Epoch 2, Batch  9200] loss: 0.422\n",
      "[Epoch 2, Batch  9600] loss: 0.428\n",
      "[Epoch 2, Batch 10000] loss: 0.443\n",
      "[Epoch 2, Batch 10400] loss: 0.361\n",
      "[Epoch 2, Batch 10800] loss: 0.449\n",
      "[Epoch 2, Batch 11200] loss: 0.403\n",
      "[Epoch 2, Batch 11600] loss: 0.374\n",
      "[Epoch 2, Batch 12000] loss: 0.381\n",
      "[Epoch 2, Batch 12400] loss: 0.395\n",
      "[Epoch 2, Batch 12800] loss: 0.361\n",
      "[Epoch 2, Batch 13200] loss: 0.368\n",
      "[Epoch 2, Batch 13600] loss: 0.367\n",
      "[Epoch 2, Batch 14000] loss: 0.393\n",
      "[Epoch 2, Batch 14400] loss: 0.399\n",
      "[Epoch 2, Batch 14800] loss: 0.362\n",
      "[Epoch 2, Batch 15200] loss: 0.396\n",
      "[Epoch 2, Batch 15600] loss: 0.431\n",
      "[Epoch 2, Batch 16000] loss: 0.401\n",
      "[Epoch 2, Batch 16400] loss: 0.425\n",
      "[Epoch 2, Batch 16800] loss: 0.408\n",
      "[Epoch 2, Batch 17200] loss: 0.372\n",
      "[Epoch 2, Batch 17600] loss: 0.350\n",
      "[Epoch 2, Batch 18000] loss: 0.362\n",
      "[Epoch 2, Batch 18400] loss: 0.408\n",
      "[Epoch 2, Batch 18800] loss: 0.315\n",
      "[Epoch 2, Batch 19200] loss: 0.451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libc++abi: terminating due to uncaught exception of type std::__1::system_error: Broken pipe\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x1068f5af0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/joelgc/2026/deeplearn440/env/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/Users/joelgc/2026/deeplearn440/env/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1628, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/multiprocessing/process.py\", line 149, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/multiprocessing/popen_fork.py\", line 40, in wait\n",
      "    if not wait([self.sentinel], timeout):\n",
      "  File \"/Users/joelgc/2026/deeplearn440/env/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py\", line 73, in handler\n",
      "    _error_if_any_worker_fails()\n",
      "RuntimeError: DataLoader worker (pid 80675) is killed by signal: Abort trap: 6. \n",
      "libc++abi: terminating due to uncaught exception of type std::__1::system_error: Broken pipe\n",
      "libc++abi: terminating due to uncaught exception of type std::__1::system_error: Broken pipe\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# back prop\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# update weights\u001b[39;00m\n\u001b[1;32m     18\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/2026/deeplearn440/env/lib/python3.9/site-packages/torch/_tensor.py:647\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    637\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    638\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    639\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    640\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    645\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    646\u001b[0m     )\n\u001b[0;32m--> 647\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    648\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    649\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/2026/deeplearn440/env/lib/python3.9/site-packages/torch/autograd/__init__.py:354\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    349\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    351\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 354\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    362\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/2026/deeplearn440/env/lib/python3.9/site-packages/torch/autograd/graph.py:829\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    827\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 829\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    833\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "for epoch in range(20):\n",
    "    running_loss = 0.0\n",
    "    print_interval = 400\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        \n",
    "        inputs, labels = data\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward\n",
    "        outputs = fcn2(inputs)\n",
    "        # calculate loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # back prop\n",
    "        loss.backward()\n",
    "        # update weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # stats \n",
    "        running_loss += loss.item()\n",
    "        if i % print_interval == print_interval - 1:\n",
    "            avg_loss = running_loss / print_interval\n",
    "            print(f'[Epoch {epoch + 1}, Batch {i + 1:5d}] loss: {avg_loss:.3f}')\n",
    "            running_loss = 0.0 \n",
    "print('finished training')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603feed3",
   "metadata": {},
   "source": [
    "## Test Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bbe934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final accuracy on 10000 test images: 85.4%\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        \n",
    "        images, labels = data\n",
    "        \n",
    "        # raw model scores\n",
    "        outputs = fcn2(images)\n",
    "        # extract highest score\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        # count total images processes so far\n",
    "        total += labels.size(0)\n",
    "        # count how many in this batch matches the labels\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total \n",
    "print(f'Final accuracy on {total} test images: {accuracy:.1f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
